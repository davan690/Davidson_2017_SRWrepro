---
title: "NZ SRW Calving interval report"
author: "Anthony Davidson"
date: '`r format(Sys.time(), "%d %B, %Y")`'
output:
  word_document: default
  pdf_document: default
  html_document: default
geometry: margin=1in
fontsize: 14pt
---

#Raw data
<!--The data frame imported from Will is as follows:-->

```{r setup, echo=FALSE, warning = FALSE, message = FALSE}
#NZJFMS manuscript
#15032017
#Anthony Davidson

#packages
library(boot) 
library(tidyverse)
library(dplyr)
library(ggplot2)
library(qpcR)
library(pwr)
library(ggthemes)
library(gridExtra)

#set working dir
#laptop
# github file location
setwd("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data")
#setwd("C:/Users/s435389/Dropbox/NZJMFR Publication Calving interval/NZJMFR Calving Analysis/Final code for publication")
#desktop
#setwd("C:/Users/s435389/Dropbox (Population_Stats)/NZJMFR Publication Calving interval/NZJMFR Calving Analysis/Final code for publication")

###############################DATA####################################
Data<- read.csv("RawCI.csv", header=T, quote="\"")

#Structure of data set
#str(Data)

#year recorded
Year<-unique(Data$Calves.1)

#calving interval observed in 2010
year2010a<-c(3,3,2)
year2010 <- filter(Data,Calves.1 < 2011)
year2010 <- year2010$Interval.1[!is.na(year2010$Interval.1)]

#calving interval observed in 2011
year2011a<-c(3,3,2,3,3,3,3,3,3,3,3,3,3,3,2)
year2011 <- filter(Data,Calves.1 < 2012)
year2011 <- year2011$Interval.1[!is.na(year2011$Interval.1)]

#calving interval observed in 2012
year2012a<-c(3,3,2,3,3,3,3,3,3,3,3,3,3,3,2,
            6,4,4,4,4,4,3,3,3,3)
year2012 <- filter(Data,Calves.1 < 2013)
year2012 <- year2012$Interval.1[!is.na(year2012$Interval.1)]

#calving interval observed in 2013
year2013a<-c(3,3,2,3,3,3,3,3,3,3,3,3,3,3,2,
            6,4,4,4,4,4,3,3,3,3,
            6,5,4,4,4,4,4,3,3,3,3,3,3,3,3,3,3,3,2,2)
full <- c(Data$Interval.1,Data$Interval.2)
year2013<- full[!is.na(unlist(full))]
```

The data is then converted into intervals for each of the years 2010, 2011, 2012 and 2013.

```{r basic, echo=FALSE, message=FALSE, warning=FALSE}
#Confidence intervals
#2010
mean2010<-sum(year2010)/length(year2010)
s2010<-sd(year2010)
SE2010<-s2010/(sqrt(length(year2010)))
n2010<-(length(year2010))
low.qt2010 <- mean2010-(qt(0.975,length(year2010))*SE2010)
high.qt2010 <- mean2010+(qt(0.975,length(year2010))*SE2010)

#2011
mean2011<-sum(year2011)/length(year2011)
s2011<-sd(year2011)
SE2011<-s2011/(sqrt(length(year2011)))
n2011<-(length(year2011))
low.qt2011 <- mean2011-(qt(0.975,length(year2011))*SE2011)
high.qt2011 <- mean2011+(qt(0.975,length(year2011))*SE2011)

#2012
mean2012<-sum(year2012)/length(year2012)
s2012<-sd(year2012)
SE2012<-s2012/(sqrt(length(year2012)))
n2012<-(length(year2012))
low.qt2012 <- mean2012-(qt(0.975,length(year2012))*SE2012)
high.qt2012 <- mean2012+(qt(0.975,length(year2012))*SE2012)

#2013
mean2013<-sum(year2013)/length(year2013)
s2013<-sd(year2013)
SE2013<-s2013/(sqrt(length(year2013)))
n2013<-(length(year2013))
low.qt2013 <- mean2013-(qt(0.975,length(year2013))*SE2013)
high.qt2013 <- mean2013+(qt(0.975,length(year2013))*SE2013)

#Makes data frame to plot
n <- c(length(year2010),length(year2011),length(year2012),length(year2013))
mY <- c(mean(year2010),mean(year2011),mean(year2012),mean(year2013))
year <- Year
low.qt <- c(low.qt2010,low.qt2011,low.qt2012,low.qt2013)
high.qt <- c(high.qt2010,high.qt2011,high.qt2012,high.qt2013)
sd <- c(s2010,s2011,s2012,s2013)
sum.dat <- cbind(year,n,mY,low.qt,high.qt,sd)
sum.dat <-  as.data.frame(sum.dat)

```

A table of the raw results as the year increase

```{r raw table, echo=FALSE}
library(knitr)
kable(sum.dat, format = "markdown")
```

The raw intervals can be presented as different means and confidence intervals as the length of the study increases:

```{r raw graph, echo=FALSE, message=FALSE, warning=FALSE}
#plot data
ggplot(sum.dat, aes(y = mY, x = year)) +
  geom_point() +
  geom_line() +
  geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.1) +
  theme_bw()
```

We can also plot these as bar charts that show this more obviously:

```{r raw graph 2, echo=FALSE, fig.height=6, fig.width=6, message=FALSE, warning=FALSE}

#PLOTS
par(mfrow=c(2,2))

plot(factor(year2010),xlim=c(0,6),ylim=c(0,40))
title(main="a)",sub="Sample size 3", ylab="Frequency",xlab="Calving interval",
      cex.main = 1.5,   font.main= 4, col.main= "blue",
      cex.sub = 1, font.sub = 3, col.sub = "red")
box()

plot(factor(year2011),xlim=c(0,6),ylim=c(0,40))
title(main="b)",sub="Sample size 15", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",
      cex.sub = 1, font.sub = 3, col.sub = "red")
box()

plot(factor(year2012),xlim=c(0,6),ylim=c(0,40))
title(main="c)",sub="Sample size 25", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",
      cex.sub = 1, font.sub = 3, col.sub = "red")
box()

plot(factor(year2013),xlim=c(0,6),ylim=c(0,40))
title(main="d)",sub="Sample size 45", ylab="Frequency",xlab="Calving interval",col.main=4,cex.main = 1.5,   font.main= 4, col.main= "blue",
      cex.sub = 1, font.sub = 3, col.sub = "red")
box()

```
 
What is interesting is that in 2011 there were more intervals that subsequently reduced the standard error of the estimate and the precision increased. 


**My idea of why this has happened is as follows:**

At the time of collection in 2011 the number of possible intervals greater than 5 was very unlikely (as there where only 5 years of research). This meant that the overall error of the estimate was reduced as there was very few "chances" of obtaining a calving interval of 5 or 6 even though there may have been quite a few. The following estimates then picked these up and the error in the estimate increased again. 
 
###Publication plot (Figure 2)
```{r raw graph 3, echo=FALSE, fig.height=6, fig.width=6, message=TRUE, warning=TRUE}
library(qpcR)
#data in one way for plot
rawdata <- qpcR:::cbind.na(year2010,year2011,year2012,year2013)
rawdata <- as.data.frame(rawdata)

#in correct format for ggplot2
year2010 <- data.frame(year2010,year = c("2010"))
year2010 <- rename(year2010, interval = year2010, year = year )
year2011 <- data.frame(year2011,year = c("2011"))
year2011 <- rename(year2011, interval = year2011, year = year )
year2012 <- data.frame(year2012,year = c("2012"))
year2012 <- rename(year2012, interval = year2012, year = year )
year2013 <- data.frame(year2013,year = c("2013"))
year2013 <- rename(year2013, interval = year2013, year = year )
ggplotraw <- rbind(year2010,year2011,year2012, year2013)
ggplotraw$interval <- as.numeric(as.character(ggplotraw$interval))

#sort(year2013$interval) - sort(sample.true)


ggplot(year2013,aes(x = interval)) +
    geom_bar(alpha = 1, width = 0.9,fill = "black") +
    xlab(expression("Calving"~"interval"~(italic("years")))) +
    ylab(expression("Total"~"number"~"of"~"observations"~(italic("n")))) +
    scale_y_continuous(breaks = c(0,5,10,15,20,25,30), limits = c(0,30)) +
    theme(axis.line = element_line(colour = 'black', size = 0.65),
          axis.ticks = element_line(colour = "black", size = 0.65),
          panel.border = element_blank(), 
          panel.grid.major = element_blank(), 
          panel.grid.minor = element_blank(), 
          legend.key = element_blank(), 
          strip.background = element_rect(fill = "white", colour = "black", size = 1),
          panel.background = element_rect(fill = "white", 
            colour = NA),
          axis.text = element_text(size = rel(0.8), 
            colour = "black"))
#PLOTS
#code to store figure
# png("Figure_2_NZSRW_calving_interval_2017_highres.png", width = 12, height = 14.8, units = 'cm', res = 1200)
# dev.off()
```

<!------------------------------------------------------------>
#Missing intervals (Bradford et al. 2008)

This is a way to see what the calving interval might be if we had in fact missed calving events that happened before or after the study period.

```{r missing intervals, echo=FALSE, fig.height=10, message=FALSE, warning=FALSE}
#################################Missing calving intervals################
#Intervals modified by accounting for missed intervals
#Bradford et al. 2008

#Raw Data
RealCI <- as.numeric(year2013$interval)

#Confidence interval
xlong <- RealCI
meanlong<-sum(xlong)/length(xlong)
slong<-sd(xlong)
SElong<-slong/(sqrt(length(xlong)))
nlong<-(length(xlong))
#Standard error and confidence intervals
#2 sided t value at the 95% level = 2.093
lowqtlong <- meanlong-(qt(0.975,nlong)*SElong)
highqtlong <- meanlong+(qt(0.975,nlong)*SElong)

####################MED CI########################################
# 2x 6's and 1x 5 replaced with 3threes
MedCI <- c(RealCI[RealCI < 5],3,3,3,3,2,3)  
#sort(MedCI)
xmed<-MedCI
meanmed<-sum(xmed)/length(xmed)
smed<-sd(xmed)
SEmed<-smed/(sqrt(length(xmed)))
nmed<-(length(xmed))

#Standard error and confidence intervals
lowqtmed <- meanmed-(qt(0.975,length(xmed))*SEmed)
highqtmed <- meanmed+(qt(0.975,length(xmed))*SEmed)


############################SHORT CI##################################
#6,5 replaced with 2 year intervals

LowCI <- c(RealCI[RealCI < 4],3,3,3,3,3,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2)  
xshort<-LowCI
meanshort<-mean(xshort)
sshort<-sd(xshort)
SEshort<-sshort/(sqrt(length(xshort)))

#Standard error and confidence intervals
lowqtshort <- meanshort-(qt(0.975,length(xshort))*SEshort)
highqtshort <- meanshort+(qt(0.975,length(xshort))*SEshort)

bdata <-qpcR:::cbind.na(RealCI,MedCI,LowCI)
bdata <- as.data.frame(bdata)

#Structure of data set
#str(bdata)
```

```{r missing intervals plot, echo=FALSE, fig.height=3.5, fig.width=5.5, message=FALSE, warning=FALSE}
#Basic plots 
par(mfrow=c(1,3))
plot(factor(bdata$LowCI),main="Lowest possible interval")
plot(factor(bdata$MedCI), main="Medium possible interval")
plot(factor(bdata$RealCI),main="Observed interval")
```

```{r missing intervals plot2, fig.height=5.5, fig.width=4.5, message=FALSE, warning=FALSE, include=FALSE}
#Density basic plots 
par(mfrow=c(3,1))
plot(density(as.numeric(as.character(LowCI)),bw=.5), main="Lowest possible interval")
plot(density(as.numeric(as.character(MedCI)),bw= 0.5), main="Medium possible interval")
plot(density(as.numeric(as.character(RealCI)),bw = 0.5),main="Observed interval")
```

```{r missing intervals table, fig.height=8, message=FALSE, warning=FALSE, include=FALSE}

###################################SUMMARY############################
#Pull out important information
Sumtable<-data.frame(variable = c("low.qt","mean","high.qt","sd", "SE"),                 short=c(lowqtshort,meanshort,highqtshort,sshort,SEshort),
                     medium=c(lowqtmed,meanmed,highqtmed,smed,SEmed),
                     real=c(lowqtlong,meanlong,highqtlong,slong,SElong))

#Make dataframe to plot
n <- c(length(LowCI),length(MedCI),length(year2013$interval))
mY <- c(mean(LowCI),mean(MedCI),mean(year2013$interval))
interval <-c("Low", "Medium","Observed")
low.qt <- c(lowqtshort,lowqtmed,low.qt2013)
high.qt <- c(highqtshort,highqtmed,high.qt2013)
sd <- c(sshort,smed,s2013)
Sumtable <- cbind(interval,n,mY,low.qt,high.qt,sd)
Sumtable <-  as.data.frame(Sumtable)

 Sumtable$n <- as.numeric(as.character(Sumtable$n))
 Sumtable$mY <- as.numeric(as.character(Sumtable$mY))
 Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))
 Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))
 Sumtable$sd <- as.numeric(as.character(Sumtable$sd))
 Sumtable$interval <- as.character(Sumtable$interval)
```

###Publication plot (Not included in final publication)
```{r missing intervals plot3, echo=FALSE, fig.height=4, message=FALSE, warning=FALSE}
ggplot(Sumtable, aes(y = mY, x = interval)) +
  geom_point(size = 5) + 
  geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05,size = 1, alpha = 0.5) +
  scale_y_continuous(breaks = round(seq(2.3, 3.6, by = 0.2),1)) +
  labs(y = "Mean calving interval",x = "Calving interval modification" ) +
  geom_point(size = 3) +
  theme_classic() +
  theme_hc() +
  theme(legend.position="none")
```

The error gets smaller as the variance in the estimate decreases. We are artificially doing this here by modifying data to match what maybe more biologically possible.

```{r missing_data_table, echo=FALSE}
library(knitr)

kable(Sumtable, format = "markdown",col.names = c("Interval","Sample size", "Mean", "Lower limit", "Higher limit", "SD"))

```


<!-------------------------------------------------------------------->
#Bootstrapping

Below is the estimates from other populations of SRWs around the world.

```{r srw_data_table, echo=FALSE}
library(knitr)
setwd("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data")
srwdat <- read.csv(file = "srw_data.csv")

#str(srwdat)
kable(srwdat, format = "markdown",col.names = c("Sample size","Mean", "Lower limit", "Higher limit", "SE","Author", "Location"))

```
**Table of parameters:** This is taken directly from my Master's thesis. There may be updated estimates that need to be checked here.

##Single bootstrap with increased sample size
Bootstrap mean calving interval 1000 times and save the mean for each bootstrap sample. Here I investigate the effect of a sample size of 10,100,1000,2000 from the observed NZ calving interval.

<!--###The plot below shows a single bootstrap sample for each of the sample sizes:-->

```{r bootstrap single, echo=FALSE, fig.height=5}
############################NZ Simple sample##############################
#WITH replacement

# to try and match number of intervals observed in other populations
# find references
SAreps <- 1500 
ARreps <- 800
Aussiereps <- 2000
low <- 1000
verylow <- 100
lowest <- 10

#Very raw plots
par(mfrow=c(2,3))
plot(factor(sample(year2013$interval,lowest,replace=T)),main = "3 intervals")
plot(factor(sample(year2013$interval,verylow,replace=T)),main = "10 intervals")
plot(factor(sample(year2013$interval,low,replace=T)),main = "30 intervals")
plot(factor(sample(year2013$interval,Aussiereps,replace=T)),main = "500 intervals")
plot(factor(sample(year2013$interval,ARreps,replace=T)),main = "800 intervals")
plot(factor(sample(year2013$interval,SAreps,replace=T)),main = "1500 intervals")
```


```{r bootstrap_multiple, echo=FALSE}
#do each one 1000 times
boots <- 1000
n <- c(1:1000)


###########################n10
var10 <- paste0("n_", 1:10)
sample10 <-matrix(data = NA, ncol = lowest, nrow = boots)
colnames(sample10) <- as.list(var10)

for (i in 1:boots) {
                    sample10 [i, ] <- sample(year2013$interval,lowest,replace=T)
                        }  #i

sample10 <- as.data.frame(sample10)
sample10 <- sample10 %>%
            mutate(mean10 = rowMeans(sample10))

sample10t <- as.matrix(sample10)
sample10t <-t(sample10t)

#########################verylow sample size
#set up variable names
var100 <- paste0("n_", 1:100)

sample100 <-matrix(data = NA, ncol = verylow, nrow = boots)
colnames(sample100) <- as.list(var100)

for (i in 1:boots) {
                    sample100 [i, ] <- sample(year2013$interval,verylow,replace=T)
                        }  #i

sample100 <- as.data.frame(sample100)
sample100 <- sample100 %>%
            mutate(mean100 = rowMeans(sample100))

#########################middle one
#set up variable names
var500 <- paste0("n_", 1:500)

sample500 <-matrix(data = NA, ncol = 500, nrow = boots)
colnames(sample500) <- as.list(var500)

for (i in 1:boots) {
                    sample500 [i, ] <- sample(year2013$interval,500,replace=T)
                        }  #i

sample500 <- as.data.frame(sample500)
sample500 <- sample500 %>%
            mutate(mean500 = rowMeans(sample500))


#########################low sample size
#set up variable names
var1000 <- paste0("n_", 1:1000)

sample1000 <-matrix(data = NA, ncol = low, nrow = boots)
colnames(sample1000) <- as.list(var1000)

for (i in 1:boots) {
                    sample1000 [i, ] <- sample(year2013$interval,low,replace=T)
                        }  #i

sample1000 <- as.data.frame(sample1000)
sample1000 <- sample1000 %>%
            mutate(mean1000 = rowMeans(sample1000))

#########################AUS sample size
#set up variable names
varA <- paste0("n_", 1:2000)

sampleA <-matrix(data = NA, ncol = Aussiereps, nrow =  boots)
colnames(sampleA) <- as.list(varA)

for (i in 1:boots) {
                    sampleA [i, ] <- sample(year2013$interval,Aussiereps,replace=T)
                        }  #i

sampleA <- as.data.frame(sampleA)
sampleA <- sampleA %>%
            mutate(meanA = rowMeans(sampleA))

sampleAt <- t(sampleA)

for(i in c(1:ncol(sampleA))) {
    sampleA[,i] <- as.numeric(as.character(sampleA[,i]))
}




#COnfidence intervals

ab <- sort(sampleA$meanA)
nab <- length(ab)
#low = 25/1000
ab2.5 <- ab[25]
#high = 975/1000
ab0.97.5 <- ab[975]

ab <- sort(sampleA$meanA)
nab <- length(ab)
#low = 25/1000
ab2.5 <- ab[25]
#high = 975/1000
ab0.97.5 <- ab[975]

```

###Publication plot (Figure 3)
```{r bootstrap plot2, fig.height=5, message=FALSE, warning=FALSE, include=FALSE}
#plot the data over each other to look at change in density
par(mfrow=c(1,1))
#plot(density(sample3$mean3,bw = .15),lwd = 3,lyt = 5, main = "", xlab = "Calving interval", box = FALSE,axis = FALSE)

plot(density(sample10$mean10,bw = .05),col ="black", lty = 1, main = "", lwd = 5,ylim = c(0,8),xlim = c(2,4.5), axes=FALSE,xlab = "Calving interval")
lines(density(sample100$mean100,bw = .05),col ="black", lty = 2, lwd = 4)
lines(density(sample500$mean500,bw = .05),col ="black", lty = 3, lwd = 3)
lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 4, lwd = 2)
lines(density(sampleA$meanA,bw = .05),col ="black", lty = 5, lwd = 1)
legend('topright',title = "Legend", c("n=10, cv=8.12 ", "n=100, cv=2.43", "n=500, c.v=1.15", "n=1000, cv=0.79", "n=2000, cv=0.56"),bty = "n",
  lty = c(1,2,3,4,5), lwd = c(5,4,3,2,1), cex=.75)
axis(1,lwd=2) 
axis(2,lwd=2)

```

```{r final plot for publication1, echo=FALSE}
#final [plot]
#size defined by NZJFMR
#  195 mm (h) ? 148 mm (w).
#ylab(expression("Total"~"number"~"of"~"observations"~(italic("n")))) +

plot(density(sample10$mean10,bw = .05),col ="black", lty = 3, main = "", lwd = 1,ylim = c(0,8),xlim = c(2.5,4.5), axes=FALSE, xlab = expression("Calving"~"interval"~(italic("years"))))
lines(density(sample100$mean100,bw = .05),col ="black", lty = 4, lwd = 1)
lines(density(sample500$mean500,bw = .05),col ="black", lty = 5, lwd = 1)
lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 2, lwd = 1)
lines(density(sampleA$meanA,bw = .05),col ="black", lty = 1, lwd = 2)
legend(y = 8, x = 3.9,title = expression(bold("Sample size (n)")), c(expression(italic("n")~"="~"10"), expression(italic("n")~"="~"100"), expression(italic("n")~"="~"500"), expression(italic("n")~"="~"1000"), expression(italic("n")~"="~"2000")),bty = "n",
  lty = c(3,4,5,2,1), lwd = c(1,1,1,1,2), cex=1) 
 axis(1,lwd=2)
axis(2,lwd=2)

# PLOT CODE FOR PUBLICATION
# png("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Figures/Figure_3_NZSRW_calving_interval_2017_lowres.png", width = 14.8, height = 14.8, units = 'cm', res = 400)
# dev.off()
# 
# 
# png("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Figures/Figure_3_NZSRW_calving_interval_2017_highres.png", width = 14.8, height = 14.8, units = 'cm', res = 1200)
# 
# plot(density(sample10$mean10,bw = .05),col ="black", lty = 3, main = "", lwd = 1,ylim = c(0,8),xlim = c(2.5,4.5), axes=FALSE,xlab = expression("Calving"~"interval"~(italic("years"))))
# lines(density(sample100$mean100,bw = .05),col ="black", lty = 4, lwd = 1)
# lines(density(sample500$mean500,bw = .05),col ="black", lty = 2, lwd = 1)
# lines(density(sample1000$mean1000,bw = .05),col ="black", lty = 5, lwd = 1)
# lines(density(sampleA$meanA,bw = .05),col ="black", lty = 1, lwd = 2)
# legend(y = 8, x = 3.9,title = expression(bold("Sample size (n)")), c(expression(italic("n")~"="~"10"), expression(italic("n")~"="~"100"), expression(italic("n")~"="~"500"), expression(italic("n")~"="~"1000"), expression(italic("n")~"="~"2000")),bty = "n",
#   lty = c(3,4,2,5,1), lwd = c(1,1,1,1,2), cex=1) 
# axis(1,lwd=2)
# axis(2,lwd=2)
# 
# dev.off()
```

#Referees additional analysis 
##Suggestion one

<span style="color:red">**"If another 45 samples were collected over the next 8 years, but the mean moved from 3.31 to e.g., 3.7 years, would it be detectable with alpha = 0.05, 0.10 â€¦ ? Given that other authors have hypothesised that poor food availability would translate to increased calving intervals/calf mortalities (e.g., Cooke et al 2003, Rowntree et al 2013), being able to detect such a change would be important."**</span>

To do this it is simply a old school power analysis with the focus on the type one error (alpha) as below:

```{r referee_comment_1, echo=TRUE}
#observed sample
rev.one <- bdata$RealCI[1:45]

#sample 45 times
sample.true <- year2013$interval

#power analysis
pwr.test.results <- power.t.test(n = 45,# sample size
             delta = seq(0,0.99,0.001),  #difference between means
             sd = sd(sample.true),      #observed variation
             alternative = "one.sided", #observed test type
             sig.level = 0.05)          #significance level

#additional packages are avaliable for more complex analysis
#but have not done this as don't think it is needed

```

Here I have looked at the effect of the difference in the mean to range from the same 3.31 (delta = 0) to 4.31 (delta = 1) with the same variation as observed in the observed data.

```{r referee_comment_1_plot, echo=FALSE, message=FALSE, warning=FALSE}
#sort data into ggplot format
pwr.analysis <- as.data.frame(cbind(
                              pwr.test.results$power,
                              pwr.test.results$delta))

colnames(pwr.analysis) <- c("Power","Mean.difference")

#sort data into ggplot format
pwr.analysis.1 <- pwr.analysis %>%
  mutate(Alpha = 1- Power, 
         Mean.estimate = 3.31+Mean.difference) 
# %>%
#   select(Alpha,Mean.estimate)

#work out where the cut-off is 
a <- filter(pwr.analysis.1, Alpha < 0.05)
a[1,]

#plot data
ggplot(data = pwr.analysis.1, aes(x = Mean.estimate, y = Alpha)) +
  geom_line(size = 1.5) +
  geom_vline(xintercept = 3.903, col = "blue") +
  geom_hline(yintercept = 0.05) + 
  ggtitle("Raw data result plot (n = 45)")
```

It is interesting to note that we the minimum mean difference with a sample size of 45 that a difference between populations was observed at the 95% level would be a mean calving interval of 3.9.

Below is an additional analysis to look at the number of samples needed to find a difference the same or greater than the mean estimate for the Australian population recorded as 3.63.

```{r referee_comment_2_plot, echo=FALSE, message=FALSE, warning=FALSE}
#observed sample
rev.one <- bdata$RealCI[1:45]

#sample 45 times
sample.true <- year2013$interval

#difference
diff <- 3.63-3.31  #observed mean of australian population

#power analysis
pwr.test.results <- power.t.test(n = seq(1,200,1),# sample size
             delta = diff,  #difference between means
             sd = sd(sample.true),      #observed variation
             alternative = "one.sided", #observed test type
             sig.level = 0.05)          #significance level
   
#additional packages are avaliable for more complex analysis
#but have not done this as don't think it is needed

#sort data into ggplot format
pwr.analysis <- as.data.frame(cbind(
                              pwr.test.results$power,
                              pwr.test.results$n))

colnames(pwr.analysis) <- c("Power","Sample.size")

#sort data into ggplot format
pwr.analysis.1 <- pwr.analysis %>%
  mutate(Alpha = 1- Power)
# %>%
#   select(Alpha,Mean.estimate)

#work out where the cut-off is 
a <- filter(pwr.analysis.1, Alpha < 0.05)
a[1,]

#plot data
ggplot(data = pwr.analysis.1, aes(x = Sample.size, y = Alpha)) +
  geom_line(size = 1.5) +
  geom_vline(xintercept = 45, col = "red") +
  geom_vline(xintercept = 153, col = "blue") +
  geom_hline(yintercept = 0.05) +
  scale_y_continuous(limits = c(0,1)) +
   ggtitle("Observed difference between Australian and NZ mean")
```
Red line represents the current sample size of NZ population estimate
and blue line represents the size needed to have alpha=0.05


**Important note**

I do not this is the best approach because... 

<span style="color:red">if the sampling continues over the next 8 years, the number of observations will not increase in a linear function as the number of individuals available for recapture is growing (more individuals in database) at a different rate to the capture probability (that is hopefully constant). I will do the simulation recommended because both the editor and reviewer wanted it.</span>

I previously approached this problem by using bootstrapping and looking at the effect of the sampling size (n) increasing.


##Suggestion three

<span style="color:red">**"Is there any information for the females with the potentially missed calving events in the intervening years; e.g., were they seen without calves?"**</span>

###Individual status
I only have data for these overall data points up to 2012 so have done the analysis with this and can just add an additional year to check this.

To do this the following steps are taken:

1) Raw data I have currently looks like so:
```{r missed individuals 1, echo=FALSE}
dat <- read.csv("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data/raw_observations_2012.csv")
#data structure
glimpse(dat)

#And the second dataset
dat1<- read.csv("C:/Users/s435389/R_packages/Davidson_2017_SRWrepro/Data/RawCI.csv", header=T, quote="\"")
#data structure
glimpse(dat1)
```


2) The two data sets can be combined to reduce the data down to just individuals that have been seen with a  calf at least once.

This is important because we do not know the reproductive state of individuals until they are first seen with a calf so therefore any individuals that are in the database and have not been identified with a calf maybe juvenile and therefore not reproducing and we would be overestimating the number of possible reproductive events.

```{r missed individuals 2, echo=FALSE, message=FALSE, warning=FALSE}
##I can then modify this data to 
#restructure dataset of capture to long dataset
dat3 <- dplyr::select(dat, ID, X2006:X2012)%>%
               gather(year, count,X2006:X2012)

#add data on calves
dat4 <- full_join(dat3,dat1, by = "ID")
dat5 <- dplyr::select(dat4,ID,year,count,Yr.first.seen,Calves,Calves.1,Calves.2)

dat6 <- filter(dat5,count >0)
glimpse(dat6)

dat7 <- mutate(dat6, year = ifelse(year == "X2006","2006", year),
            year = ifelse(year == "X2007","2007", year),
            year = ifelse(year == "X2008","2008", year),
            year = ifelse(year == "X2009","2009", year),
            year = ifelse(year == "X2010","2010", year),
            year = ifelse(year == "X2011","2011", year),
            year = ifelse(year == "X2012","2012", year))

a <- group_by(dat7, ID, Yr.first.seen) %>%
  mutate(mother = ifelse(Yr.first.seen > 0, 1, 0)) %>%
  filter(mother == 1) %>%
  ungroup() %>%
  dplyr::select(ID,year,Calves,Calves.1) %>%
  filter(Calves.1<2013) %>%
  filter(!year == Calves) %>%
filter(!year ==Calves.1)

a
```

3) And overall between 2006 and 2012 only a single individual (AI09216) was identified as being a mother and was seen in 2007 without a calf. 

This individual had also not been seen with a calf until 2009 so even this individual may have been juvenile at this stage.



##Suggestions on variations of detection error and removing/increasing observed estimates

These comments are about additional data manipulation and the following estimates are plotted in the same figure as the Bradford et al 2008 modifications below.

<span style="color:red">**"Another possibility not explored is that the reported two year calving intervals could have been an error; what would the mean calving interval be in this case?"**</span>


```{r referee_comment3, echo=TRUE, message=FALSE, warning=FALSE}
greater.than.2 <- sample.true[sample.true>2]

#greater.than.2
mean.2<-sum(greater.than.2)/length(greater.than.2)
s.2<-sd(greater.than.2)
SE.2<-s2013/(sqrt(length(greater.than.2)))
n.2<-length(greater.than.2)
low.qt.2<- mean.2-(qt(0.975,length(greater.than.2))*SE.2)
high.qt.2 <- mean.2+(qt(0.975,length(greater.than.2))*SE.2)

#add it to the table from bradford data
Sumtable[4,] <- c("miss2year",n.2,mean.2,low.qt.2,
                  high.qt.2,sd(greater.than.2))

```



<span style="color:blue">**"The existing simulation could be improved by assuming imperfect detection of calving events. For example, how does the variance around the estimate of mean calving interval change when 5% of calving events are not detected, increasing the number of 5 or 6 year observed calving intervals?"**</span>


```{r different missing intervals 1, echo=TRUE}
########################### 2.2%
#parameters
boots <- 1000
n <- c(1:1000)

###round all percentages upwards
detect1 <- 44  # (45*1.02) - 45 = 0.9
detect2 <- 42   #  (45*1.05) - 45 = 2.25
detect3 <- 40  # (45*1.10) - 45 = 4.5

sample2 <-rep(NA, 1000)
sample5 <-rep(NA, 1000)
sample10 <-rep(NA, 1000)

for (i in 1:boots) {
                    sample2[i]<-mean(sample(year2013$interval,detect1,replace=T))
                    sample5[i]<-mean(sample(year2013$interval,detect2,replace=T))
                    sample10[i]<-mean(sample(year2013$interval,detect3,replace=T))
                        }  #i

######################estimates##############
sample2 <- sort(sample2)
#low = 25/1000
sample2.2.5 <- sample2[25]
#median
sample2.50 <- sample2[500]
#high = 975/1000
sample2.975 <- sample2[975]

sample5 <- sort(sample5)
#low = 25/1000
sample5.2.5 <- sample5[25]
#median
sample5.50 <- sample5[500]
#high = 975/1000
sample5.975 <- sample5[975]

sample10 <- sort(sample10)
#low = 25/1000
sample10.2.5 <- sample10[25]
#median
sample10.50 <- sample10[500]
#high = 975/1000
sample10.975 <- sample10[975]


#add it to the table from bradford data
Sumtable[5,] <- c("detect1",detect1,sample2.50,sample2.2.5,sample2.975,NA)
Sumtable[6,] <- c("detect2",detect2,sample5.50,sample5.2.5,sample5.975,NA)
Sumtable[7,] <- c("detect5",detect3,sample10.50,sample10.2.5,sample10.975,NA)
```

<span style="color:blue">**"or increasing the number of 5 or 6 year observed calving intervals?"**</span>

Here I have added twice an many 5 and 6 year intervals (5yr = 2, 6yr = 4)

```{r different missing intervals 2}
longer5.6 <- c(sample.true,5,6,6)

#greater.than.2
mean.56<-sum(longer5.6)/length(longer5.6)
s.56<-sd(longer5.6)
SE.56<-s.56/(sqrt(length(longer5.6)))
n.56<-(length(longer5.6))
low.qt.56<- mean.56-(qt(0.975,length(longer5.6))*SE.56)
high.qt.56 <- mean.56+(qt(0.975,length(longer5.6))*SE.56)

#add it to the table from bradford data
Sumtable[8,] <- c("longer.56",n.56,mean.56,low.qt.56,high.qt.56,sd(longer5.6))

###sort out numbering in dataframe
Sumtable <-  as.data.frame(Sumtable)

 Sumtable$n <- as.numeric(as.character(Sumtable$n))
 Sumtable$mY <- as.numeric(as.character(Sumtable$mY))
 Sumtable$low.qt <- as.numeric(as.character(Sumtable$low.qt))
 Sumtable$high.qt <- as.numeric(as.character(Sumtable$high.qt))
 Sumtable$sd <- as.numeric(as.character(Sumtable$sd))
 Sumtable$interval <- as.character(Sumtable$interval)
```

###Table of results
```{r missing_data_table 2, echo=FALSE}
library(knitr)

kable(Sumtable, format = "markdown",col.names = c("Interval","Sample size", "Mean", "Lower limit", "Higher limit", "SD"))

```

###Publication plot (Not included in final publication)

```{r referee_comment3_plot, echo=FALSE}
ggplot(Sumtable, aes(y = mY, x = interval)) +
  geom_point(size = 5) + 
  geom_errorbar(aes(ymin = low.qt, ymax = high.qt), width = 0.05,size = 1, alpha = 0.5) +
  scale_y_continuous(breaks = round(seq(2.3, 5, by = 0.2),1)) +
  labs(y = "Mean calving interval",x = "Calving interval modification" ) +
  geom_point(size = 3) +
  theme_classic() +
  theme_hc() +
  theme(legend.position="none")
```


